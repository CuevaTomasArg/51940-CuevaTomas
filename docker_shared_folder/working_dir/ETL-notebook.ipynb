{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "871f5791-a3fc-4cbd-a563-e9bbec966221",
   "metadata": {},
   "source": [
    "# Segunda entrega - 51940 Cueva Tomas\n",
    "En este notebook se desarrolla un proceso ETL. El mismo consiste de la extracción de datos de la API de CoinGecko, su transformación y filtrado a través de la biblioteca Pandas, finalizando con la carga de los datos utilizando PySpark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5611bed",
   "metadata": {},
   "source": [
    "## Instalo bibliotecas y llamo a los modulos del paquete etl de este directorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2f06d1c-ceae-4031-b70d-059ae90a19c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/jovyan/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.0.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (2.28.2)\n",
      "Requirement already satisfied: SQLAlchemy in /opt/conda/lib/python3.10/site-packages (2.0.10)\n",
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting pyspark\n",
      "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m243.6/310.8 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:47\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pandas requests SQLAlchemy psycopg2-binary pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f1b9ad4-b00a-4ddc-aa9e-e3aaa050f9b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01metl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m(\n\u001b[1;32m      2\u001b[0m     extract_CoinGecko_API \u001b[38;5;28;01mas\u001b[39;00m extract,\n\u001b[1;32m      3\u001b[0m     transform_CoinGecko_API \u001b[38;5;28;01mas\u001b[39;00m transform,\n\u001b[1;32m      4\u001b[0m     load_pyspark_redshift_connectr \u001b[38;5;28;01mas\u001b[39;00m load\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[0;32m/home/coder/working_dir/etl/load_pyspark_redshift_connectr.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m environ \u001b[38;5;28;01mas\u001b[39;00m env\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mLoad\u001b[39;00m():\n\u001b[1;32m      6\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m    Clase para cargar datos en Redshift desde Spark utilizando Pyspark.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "from etl import(\n",
    "    extract_CoinGecko_API as extract,\n",
    "    transform_CoinGecko_API as transform,\n",
    "    load_pyspark_redshift_connectr as load\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a77aa1d",
   "metadata": {},
   "source": [
    "## Inicializo las clases de los modulo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f3eaae7-35ba-4c6d-95d2-7f190007fc4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "extr = extract.Extract(\"https://api.coingecko.com/api/v3/\")\n",
    "ld = load.Load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22fad5d-4e03-4e9b-a9d7-80c7fa067c03",
   "metadata": {},
   "source": [
    "## 100 criptos con mayor capitalización bursatil\n",
    "En las siguientes celdas se extraen los datos de las 100 criptomonedas con mayor capitalizazción bursatil, se convierten en un dataframe y se cargan a su tabla correspondiente de redshift,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfcf2fe4-0bf2-4c22-ae2a-62b0aad0db0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_top = extr.get_criptos_top()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "270de2f8-db9d-4991-9f48-f911497d4422",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_top = transform.transformation_top(json_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93fc3ceb-9667-45ce-ab23-3c48b1494dba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 21 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   id                                100 non-null    object \n",
      " 1   symbol                            100 non-null    object \n",
      " 2   name                              100 non-null    object \n",
      " 3   current_price                     100 non-null    float64\n",
      " 4   market_cap                        100 non-null    int64  \n",
      " 5   market_cap_rank                   100 non-null    int64  \n",
      " 6   total_volume                      100 non-null    float64\n",
      " 7   high_24h                          100 non-null    float64\n",
      " 8   low_24h                           100 non-null    float64\n",
      " 9   price_change_24h                  100 non-null    float64\n",
      " 10  price_change_percentage_24h       100 non-null    float64\n",
      " 11  market_cap_change_24h             100 non-null    float64\n",
      " 12  market_cap_change_percentage_24h  100 non-null    float64\n",
      " 13  circulating_supply                100 non-null    float64\n",
      " 14  ath                               100 non-null    float64\n",
      " 15  ath_change_percentage             100 non-null    float64\n",
      " 16  ath_date                          100 non-null    object \n",
      " 17  atl                               100 non-null    float64\n",
      " 18  atl_change_percentage             100 non-null    float64\n",
      " 19  atl_date                          100 non-null    object \n",
      " 20  last_updated                      100 non-null    object \n",
      "dtypes: float64(13), int64(2), object(6)\n",
      "memory usage: 16.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_top.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c0e817e-dcae-4cb2-8af3-74e60a9657da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table = \"criptos_market_cap\"\n",
    "ld.execute(df_top, table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a8f294",
   "metadata": {},
   "source": [
    "### Market chart de las top 10\n",
    "Utilizando los datos del dataframe del top 100, vamos a obtener el market chart de las 10 primeras del top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dca640a2-fc9d-4b36-aca2-def1ff05ab1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id_column = df_top['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27c85cc2-eeef-4cf6-89e2-f896d524ab96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id_array = id_column.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4a7c07",
   "metadata": {},
   "source": [
    "Luego ded obtener el array con todos los id, vamos a iterar 10 veces sobre el contenido del array, vamos a extraer los datos y transformarlos con las funciones de los modulos \"extr\" y \"transform\", para finalmente concatenarlos en un unico DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "431e4d78-cb21-41ae-92ad-37ddbde1be62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solicitud exitosa\n",
      "Solicitud exitosa\n",
      "Solicitud exitosa\n",
      "Solicitud exitosa\n",
      "Solicitud exitosa\n",
      "Solicitud exitosa\n",
      "Solicitud exitosa\n",
      "Solicitud exitosa\n",
      "Solicitud exitosa\n",
      "Solicitud exitosa\n"
     ]
    }
   ],
   "source": [
    "df_all_market_charts = pd.DataFrame(columns = ['timestamp', 'prices', 'market_caps', 'total_volumes', 'cripto'])\n",
    "\n",
    "for i in range(0,10):\n",
    "    data = extr.get_market_chart(id_array[i])\n",
    "    df = transform.json_to_df_market_chart(data,id_array[i])\n",
    "    df_all_market_charts = pd.concat([df_all_market_charts, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49c81a3b-34ae-4767-ac2c-01766221844b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25613 entries, 0 to 25612\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   timestamp      25613 non-null  object \n",
      " 1   prices         25613 non-null  float64\n",
      " 2   market_caps    25610 non-null  float64\n",
      " 3   total_volumes  25613 non-null  float64\n",
      " 4   cripto         25613 non-null  object \n",
      "dtypes: float64(3), object(2)\n",
      "memory usage: 1000.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_all_market_charts.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcb73d82-616f-4214-b6e6-21396646b219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejecutando ETL\n",
      "Convertir el DataFrame de pandas a un PySpark DataFrame\n",
      "DataFrame[timestamp: bigint, prices: double, market_caps: double, total_volumes: double, cripto: string]\n",
      "Cargar el PySpark DataFrame en Redshift\n",
      "Dataframe subido\n"
     ]
    }
   ],
   "source": [
    "table = \"market_chart_criptos\"\n",
    "ld.execute(df_all_market_charts, table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
